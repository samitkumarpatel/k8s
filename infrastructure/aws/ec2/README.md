
# Kubernetes Installation
### 3 node Infrastructure with aws ec2.

### Prerequisites

Ensure `terraform` and `ansible` are installed.

### Folder Structure

After cloning, your `ec2` folder should look like this:

```sh
├── inventory.yml
├── playbook.yml
├── main.tf
└── README.md
```

### Infrastructure Creation with Terraform

> On this stage I assume you have aws key and secret configure on your machine or where ever you are trying to run the terrform command.

```sh
# Initialize Terraform:
terraform init

# Validate the configuration
terraform validate

# Plan and apply the infrastructure:
terraform plan -out plan.out
terraform apply plan.out
```

> Note: With terraform by the help of ansibel provider we are instructing terraform to create a dynamic ansible inventory for us

> Terraform also will create a `ssh key` file for us to be use for `ansible` or `ssh` command.

### Configuration Management with ansible

> Note: `ansible` need `cloud.terraform` collection to be installed, so that ansible will read the dynamic inventory file generated by terraform state file.

1. Install the required Ansible collection:

```sh
ansible-galaxy collection install cloud.terraform
```

2. View the dynamic inventory content

```sh
ansible-inventory -i inventory.yml --list --vars
```

3. Prepare the SSH key:

```sh
terraform output -raw ssh_key >> id_rsa.pem

chmod 400 id_rsa.pem
```

4. Ping all hosts using Ansible:

```sh
ansible -i inventory.yml all -m ping
```

5. Install Kubernetes using Ansible

```sh
ansible-playbook -i inventory.yml playbook.yml --syntax-check
```


### Kubernetes User creation

[follow this official documentation](https://kubernetes.io/docs/tasks/administer-cluster/certificates/#openssl) or follow below steps.


1. SSH into the cluster and create an **admin user**

```sh
# Generate certificate for the user
openssl req -new -newkey rsa:2048 -nodes -keyout samit.key -out samit.csr -subj "/CN=samit"

sudo openssl x509 -req -in samit.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out samit.crt -days 30

# RBAC for the user
kubectl create clusterrolebinding samit-admin-binding --clusterrole=cluster-admin --user=samit

# Create kubeconfig file for the user
kubectl config set-cluster ec2-k8s --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://<control_plain_public_ip>:6443 --kubeconfig=samit-kubeconfig

kubectl config set-credentials samit --client-certificate=samit.crt --client-key=samit.key --embed-certs=true --kubeconfig=samit-kubeconfig

kubectl config set-context ec2-k8s-samit-context --cluster=ec2-k8s --user=samit --kubeconfig=samit-kubeconfig

kubectl config use-context ec2-k8s-samit-context --kubeconfig=samit-kubeconfig

# Test If the generated config is working or not
kubectl --kubeconfig=samit-kubeconfig get pods
kubectl --kubeconfig=samit-kubeconfig get nodes

#OR
export KUBECONFIG=$(pwd)/samit-kubeconfig
kubectl get pods
kubectl getnodes
 
```

2. SSH into the cluster and create an **normal user** with minimum access:

```sh

openssl req -new -newkey rsa:2048 -nodes -keyout amit.key -out amit.csr -subj "/CN=amit"

sudo openssl x509 -req -in amit.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out amit.crt -days 30

kubectl create rolebinding amit-binding --clusterrole=view --user=amit --namespace=default

# Create kubeconfig file for the user
kubectl config set-cluster ec2-k8s --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://<control_plain_public_ip>:6443 --kubeconfig=amit-kubeconfig

kubectl config set-credentials amit --client-certificate=amit.crt --client-key=amit.key --embed-certs=true --kubeconfig=amit-kubeconfig

kubectl config set-context ec2-k8s-amit-context --cluster=ec2-k8s --user=amit --kubeconfig=amit-kubeconfig

kubectl config use-context ec2-k8s-amit-context --kubeconfig=amit-kubeconfig

# Test
kubectl --kubeconfig=amit-kubeconfig get pods #This will work and can be seen pods running on default namespace
kubectl --kubeconfig=amit-kubeconfig get nodes # Forbidden

```

### Final Steps

Copy the kubeconfig files (amit-kubeconfig and samit-kubeconfig) to your local machine.

Set the KUBECONFIG environment variable or move the files to $HOME/.kube.

### Additional Tips

To view the genrated or copied config file.

```sh
kubectl config --kubeconfig=samit-kubeconfig view
#OR
kubectl config --kubeconfig=amit-kubeconfig view
```

> Note : Some data might be base64 encoded on the config file. If you want the real data to be seen, make sure you decode it.

Sample kubeconfig file

```sh
apiVersion: v1
kind: Config
preferences: {}
clusters:
- cluster:
    certificate-authority-data: </etc/kubernetes/pki/ca.crt base64 encoded data>
    server: https://<HOST_IP>:6443
  name: kubernetes
contexts:
- context:
    cluster: kubernetes
    user: <username>
  name: admin-context
users:
- name: <username>
  user:
    client-certificate-data: <path/to/user/file.crt>
    client-key-data: <path/to/user/file.key>
current-context: admin-context
```

You can create custom roles and role bindings using Kubernetes manifests as well. The manifest looks like below

```yml
# Developer role with watch access
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: developer
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["watch"]

# Binding the developer role to a user
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: developer-binding
  namespace: default
subjects:
- kind: User
  name: developer-user
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: developer
  apiGroup: rbac.authorization.k8s.io

# Deployment role with full access
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: deployer
rules:
- apiGroups: [""]
  resources: ["*"]
  verbs: ["*"]

# Binding the deployer role to a user
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: deployer-binding
subjects:
- kind: User
  name: deployer-user
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: deployer
  apiGroup: rbac.authorization.k8s.io

```

[back](../../../README.md)
